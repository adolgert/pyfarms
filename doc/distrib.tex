\documentclass{article}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{xspace}
\usepackage{xcolor}
\usepackage{listings}

\title{Sampling Stochastic Distributions for Discrete Events in Continuous Time}
\author{Drew Dolgert}
\date{\today}

\newcommand{\code}[1]{\texttt{#1}}

\begin{document}
\maketitle


\section{Introduction}
Simulation of discrete stochastic events in continuous time requires
drawing samples from continuous distributions. Drawing samples
is complicated by two factors. First,
we need to sample a distribution given that it has not yet fired
by a given time. Sec.~\ref{sec:shifted} discusses how to do this.
Second, the distributions are resampled according to rules required
to use Gibson and Bruck's Next Reaction algorithm, or Anderson's Next
Reaction algorithm. These algorithms use the same uniform
random variate, but with change the hazard rate.
This, too, is shown in Sec.~\ref{sec:shifted}.

As a result, none of the standard libraries in C++, Julia,
Python, or R can do the sampling required. Therefore, this
document walks through a specific set of distributions
with details on implementation given available transcendental functions.

\tableofcontents

\section{Shifted Absolute Distributions\label{sec:shifted}}
Our mission is to express probability distributions
with respect to some enabling time $t_e$ and then, after
some later time $t_0$, to perform three operations, sampling,
integration of the hazard, and the inverse of integration of
the hazard.

Given a cumulative distribution,we normally write
\begin{equation}
  F(t)=1-e^{-\int_{0}^t \lambda(s)ds}\label{eqn:simplecdf}
\end{equation}
or
\begin{equation}
  F(t)=\int_0^t f(s)ds,
\end{equation}
but for distributions in absolute time, meaning they are shifted
by $t_e$, it is
\begin{equation}
  F(t,t_e)=1-e^{-\int_{0}^{t-t_e} \lambda(s)ds}
\end{equation}
or
\begin{equation}
  F(t,t_e)=\int_{0}^{t-t_e} f(s)ds.
\end{equation}
The call for $F(t)$ is \code{cdf(t)}, and $F(t,t_e)$ is \code{cdf($t-t_e$)}.

Now let's sample the distribution after some time $t_0>=t_e$, at which time
we normalize the distribution to its remaining probability. We can
think of this best with survivals, $G(t)=1-F(t)$. In words, the probability of
survival from $t_e$ to time $t$ ($G(t,t_e)$) is the probability
of survival from $t_e$ to $t_0$ ($G(t_0,t_e$)
\emph{and} the probability of survival from $t_0$ to $t$ ($G(t,_0,t_e)$).
\begin{equation}
  G(t,t_e)=G(t_0,t_e)G(t,t_0,t_e)
\end{equation}
Written in terms of hazards, this is
\begin{equation}
  e^{-\int_{0}^{t-t_e} \lambda(s)ds}=e^{-\int_{0}^{t_0-t_e} \lambda(s)ds}
    e^{-\int_{t_0-t_e}^{t-t_e} \lambda(s)ds},
\end{equation}
where the hazard is the same zero-based hazard from Eq.~\ref{eqn:simplecdf}.
Therefore, given the initial survival, expressed since the enabling time $t_e$,
the scaled survival is
\begin{equation}
  G(t,t_0,t_e)=G(t,t_e)/G(t_0,t_e).
\end{equation}
In terms of cumulative distribution functions,
\begin{eqnarray}
  F(t,t_0,t_e)&=&1-\frac{1-F(t,t_e)}{1-F(t_0,t_e)} \\
          &=&\frac{F(t,t_e)-F(t_0,t_e)}{1-F(t_0,t_e)}\label{eqn:shiftcum} \\
\end{eqnarray}
In terms of the function calls, that means
% The NoHyper gets rid of a conflict between hyperref and listing.
\begin{NoHyper}\begin{lstlisting}
  cdf(t, t0, te)=(cdf(t-te)-cdf(t0-te))/(1-cdf(t0,te))
\end{lstlisting}
\end{NoHyper}

\begin{table}
\begin{tabular}{ll} \hline
\code{cdf(d,t)} & $F_d(t)$ \\
\code{quantile(d,q)} & $F_d^{-1}(q)$ \\
\code{logcdf(d,t)} & $\ln(F_d(t))$ \\
\code{ccdf(d,t)} & $G_d(t)$ \\
\code{logccdf(d,t)} & $-\int_0^t \lambda_d(s)ds$ \\
\code{quantile(d,q)} & $F_d^{-1}(q)$ \\
\code{cquantile(d,q)} & $F_d^{-1}(1-q)=G_d^{-1}(q)$ \\
\code{invlogcdf(d,lp)} & $F_d^{-1}(e^{l_p})$ \\
\code{invlogccdf(d,lp)} & $G_d^{-1}(e^{l_p})$ or $-\int_0^{t(l_p)}\lambda(s)ds=l_p$ \\\hline
\end{tabular}
\caption{Translation of methods into math.\label{fig:methodmath}}
\end{table}

In practice, sampling algorithms are specific to particular distributions.
They are formally equivalent to drawing a uniform random variable between
0 and 1, which we call $U$, and solving $U=F(t')$ for $t'$.
For the case of interest, where the distribution has an enabling time, $t_e$,
and is being observed after survival to a time $t_0$, sampling is formally
a solution $t'$ to $U=F(t', t_0, t_e)$. Looking back at Eq.~\ref{eqn:shiftcum},
we can write this as
\begin{eqnarray}
 U&=&F(t,t_0,t_e) \\
  &=&\frac{F(t,t_e)-F(t_0,t_e)}{1-F(t_0,t_e)} \\
U(1-F(t_0,t_e))&=&F(t,t_e)-F(t_0,t_e) \\
F(t,t_e)&=&U(1-F(t_0,t_e))+F(t_0,t_e) \\
F(t-t_e)&=&U(1-F(t_0-t_e))+F(t_0-t_e) \\
t-t_e &=& F^{-1}\left[U(1-F(t_0-t_e))+F(t_0-t_e)\right] \\
t &=& t_e+F^{-1}\left[U(1-F(t_0-t_e))+F(t_0-t_e)\right]
\end{eqnarray}
Using the inverse \textsc{cdf} from Table~\ref{fig:methodmath},
the inverse of this shifted quantile is
\begin{lstlisting}
  quantile(U, t0, te)=te+quantile(U+(1-U)*cdf(t0-te))
\end{lstlisting}
This would be a way to sample any distribution with a \textsc{cdf} and
quantile, but likely badly.

Sometimes the inverse \textsc{cdf} is unavailable, in favor if the
inverse survival, in which case
\begin{eqnarray}
F(t-t_e)&=&U(1-F(t_0-t_e))+F(t_0-t_e) \\
G(t-t_e)&=&1-U(1-F(t_0-t_e))-F(t_0-t_e) \\
t-t_e &=& G^{-1}\left[1-U(1-F(t_0-t_e))-F(t_0-t_e)\right] \\
t &=& t_e+G^{-1}\left[1-U(1-F(t_0-t_e))-F(t_0-t_e)\right]
\end{eqnarray}
The equation then becomes
\begin{lstlisting}
  quantile(U, t0, te)=te+cquantile(1-U+(U-1)*cdf(t0-te))
\end{lstlisting}

The next two pieces concern the hazard. The goal is to find the integral
of the hazard between two absolute times, $t_1$ and $t_2$, where both
are $t_{1,2}\ge t_0$. This is
\begin{equation}
  \int_{t_1-t_e}^{t_2-t_e} \lambda(s)ds=\int_{0}^{t_2-t_e} \lambda(s)ds
  	-\int_{0}^{t_1-t_e} \lambda(s)ds.
\end{equation}
In terms of the given methods, this would be, noting the minus sign
in the table,
\begin{lstlisting}
  hazard_int(t1, t2, te)=logccdf(t1-te)-logccdf(t2-te)
\end{lstlisting}

Last is the inverse hazard. We want to solve for $t'$ in
\begin{equation}
  x=\int_{t_0-t_e}^{t'-t_e}\lambda(s)ds.
\end{equation}
Expanding as before, this is
\begin{eqnarray}
  x&=&\int_{0}^{t'-t_e}\lambda(s)ds-\int_{0}^{t_0-t_e}\lambda(s)ds \\
  x+\int_{0}^{t_0-t_e}\lambda(s)ds&=&\int_{0}^{t'-t_e}\lambda(s)ds \\
  -x-\int_{0}^{t_0-t_e}\lambda(s)ds&=& -\int_{0}^{t'-t_e}\lambda(s)ds \\
  l_p&=&-x+\left[-\int_{0}^{t_0-t_e}\lambda(s)ds\right] \\
  l_p&=&-\int_{0}^{t'-t_e}\lambda(s)ds
\end{eqnarray}
Translating this into equations, we get
\begin{lstlisting}
  lp=-x+logccdf(t0-te)
  inv_hazard_int(x, t0, te)=te+invlogccdf(lp)
\end{lstlisting}

In order to calculate the likelihood of a trajectory of
a larger system of transitions, it is possible to ask,
at each time step, what is the likelihood of a particular
transition firing next at a particular time.
This value is the probability the whole system
survives to that future time,
\begin{equation}
  \prod_i G_i(t_0, t_f, t_e)
\end{equation}
multiplied by the likelihood
that transition will fire at that time, $f(t_0, t_f, t_e)=F'(t_0, t_f, t_e)$.
The log-likelihood of survival is then
\begin{equation}
  \sum_i \ln G_i(t_0, t_f, t_e)=-\sum_i \int_{t_0}^{t_f}\lambda(s,t_e)ds.
\end{equation}
This can be found from integrated hazards, already calculated.
The likelihood for the firing transition includes the density,
rescaled to account for not yet having fired,
\begin{equation}
  f(t_0, t_f, t_e)=f(t,t_e)/G(t_0, t_e).
\end{equation}
Its log will be
\begin{equation}
  \ln f(t_0, t_f, t_e)=\ln f(t,t_e) - \ln G(t_0, t_e)=
  \ln f(t,t_e)+\int_{t_e}^{t_0}\lambda(s, t_e)ds.
\end{equation}


\section{Verification of Distribution Implementations}

These distributions support three functions, sample, integrate
hazard, and the inverse of integrating hazard. We have to test
these for various conditions of distribution parameters,
enabling times, and current times.

\begin{enumerate}

\item Where theoretical bounds are known, they will be used to verify
implementations. For instance, the expected mean of an 
exponential distribution is the inverse of its hazard rate,
with suitable ninety-fifth percentile bounds.

\item The integral and its inverse should be inverses.

\item While these distributions support odd methods, they
can be compared with samples from known distributions.
The first option is to sample something known from the standard
library of special functions and then use a Kolmogorov-Smirnov
test for comparison.

\item There is a second way to sample these distributions using
the inverse hazard integral and hazard integral. This, too,
can be compared using Kolmogorov-Smirnov.

\item Plots help. We could make plots and compare with copies
of known examples.

\end{enumerate}

%%%%%%%%%%%%%%%%%%% LOG-LOGISTIC %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Log-Logistic}
Working from wikipedia, because that's smart.
\begin{equation}
  F(x;\alpha, \beta)=\frac{1}{1+(x/\alpha)^{-\beta}}.
\end{equation}
We shift this to
\begin{equation}
  F(t, t_e)=\frac{1}{1+((t-t_e)/\alpha)^{-\beta}}.
\end{equation}
The pdf is
\begin{equation}
  f(x;\alpha, \beta)=\frac{(\beta/\alpha)(x/\alpha)^{\beta-1}}
  {(1+(x/\alpha)^\beta)^2}.
\end{equation}
The quantile is
\begin{equation}
  F^{-1}(p; \alpha, \beta)=\alpha \left(\frac{p}{1-p}\right)^{1/\beta}.
\end{equation}
Survival
\begin{equation}
  G(t)=1-F(t)=\frac{1}{1+(t/\alpha)^\beta}.
\end{equation}
Hazard
\begin{equation}
  \lambda(t)=\frac{f(t)}{G(t)}=\frac{(\beta/\alpha)(t/\alpha)^{\beta-1}}
  {1+(t/\alpha)^\beta}
\end{equation}
Lastly, we need \code{invlogccdf(d,lp)}, which is $G_d^{-1}(e^{l_p})$,
or $-\int_0^t(l_p)\lambda(s)ds=l_p$.
\begin{eqnarray}
  l_p&=&\ln(G(t)) \\
  e^{l_p}&=&G(t) \\
  e^{l_p}&=&\frac{1}{1+(t/\alpha)^\beta} \\
  e^{-l_p}&=&1+(t/\alpha)^\beta \\
  (t/\alpha)^\beta&=&  1-e^{-l_p}\\
  t/\alpha&=& (1-e^{-l_p})^{1/\beta}\\
   t&=&\alpha(1-e^{-l_p})^{1/\beta}\\
\end{eqnarray}



%%%%%%%%%%%%%%%%% GAMMA %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Gamma}
We will define parameters from the shape $\alpha$ and rate $\beta$,
such that the \textsc{pdf} is
\begin{equation}
  f(x)=\frac{\beta^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{-\beta x}
\end{equation}
where
\begin{equation}
  \Gamma(t)=\int_0^\infty x^{t-1}e^{-x}dx.
\end{equation}
The \textsc{cdf} is
\begin{equation}
  F(x;\alpha,\beta)=\frac{\gamma(\alpha,\beta x)}{\Gamma(\alpha)}
\end{equation}
where $\gamma$ is the (lower) incomplete gamma function,
\begin{equation}
  \gamma(x;\alpha)=\int_0^x t^{\alpha-1}e^{-t}dt
\end{equation}

In our back pocket, from \texttt{Boost::Math}, are
$\Gamma(x)$, $\ln(|\Gamma(x)|)$, digamma, which is
\begin{equation}
  \psi(x)=\frac{d}{dx}\ln(\Gamma(x))=\frac{\Gamma'(x)}{\Gamma(x)},
\end{equation}
gamma ratio, which is $\Gamma(a)/\Gamma(b)$,
gamma delta ratio, which is $\Gamma(a)/\Gamma(a+\Delta)$,
and the set of incomplete gamma functions.
In order, they are normalized lower incomplete, normalized upper, incomplete
full (non-normalized) lower incomplete, and full (non-normalized)
upper incomplete gamma functions.
\begin{eqnarray}
  \mbox{gamma\_p}(a,z)&=&\frac{\gamma(a,z)}{\Gamma(a)}=\frac{1}{\Gamma(a)}
     \int_0^zt^{a-1}e^{-t}dt \\
  \mbox{gamma\_q}(a,z)&=&\frac{\Gamma(a,z)}{\Gamma(a)}=\frac{1}{\Gamma(a)}
     \int_z^0t^{a-1}e^{-t}dt \\
  \mbox{tgamma\_lower}(a,z)&=&\gamma(a,z)=
     \int_0^zt^{a-1}e^{-t}dt \\
  \mbox{tgamma}(a,z)&=&\Gamma(a,z)=\frac{1}{\Gamma(a)}
     \int_z^0t^{a-1}e^{-t}dt \\
\end{eqnarray}
There are a set of inverses of incomplete gamma functions
and derivatives of incomplete gamma functions.
OK, back to what we need.
\begin{eqnarray}
  F(x;\alpha,\beta)&=&\mbox{gamma\_p}(\alpha, \beta x) \\
  F^{-1}(y;\alpha,\beta)&=&\mbox{gamma\_p\_inv}(\alpha, y)/\beta
\end{eqnarray}

The hazard integral, in terms of the cdf, is
\begin{eqnarray}
 \int_{t_1-t_e}^{t_2-t_e}\lambda(s)ds&=&-\ln(1-F(t_2-t_e))+\ln(1-F(t_1-t_e)) \\
 &=& \ln\left[\frac{1-F(t_1-t_e)}{1-F(t_2-t_e)}\right].
\end{eqnarray}
Can we simplify this into something provided?
\begin{eqnarray}
\int_{t_1-t_e}^{t_2-t_e}\lambda(s)ds & = & \ln\left[\frac{1-\frac{\gamma(\alpha,\beta (t_1-t_e))}{\Gamma(\alpha)}}{1-\frac{\gamma(\alpha,\beta (t_2-t_e))}{\Gamma(\alpha)}}\right] \\
 & = & \ln\left[\frac{\Gamma(\alpha)-\gamma(\alpha,\beta (t_1-t_e))}
 {\Gamma(\alpha)-\gamma(\alpha,\beta (t_2-t_e))} \right] \\
\gamma(\alpha,\beta (t_1-t_e)) & = & \int_0^{\beta(t_1-t_e)} t^{\alpha-1}e^{-t}dt
\end{eqnarray}
It looks like we might do best just with
\begin{lstlisting}
Ga=tgamma(a)
hazint(te, t1, t2)=log((Ga-tgamma_lower(a,b*(t1-te)))/
    (Ga-tgamma_lower(a,b*(t2-te))))
\end{lstlisting}

Our other goal for Gamma distributions is to get the inverse hazard.
This can be seen as two steps. First find the integral
\begin{equation}
  l_p=-x+\left[\int_0^{t0-t_e}\lambda(s)ds\right].
\end{equation}
Then solve for $t'$ in
\begin{equation}
  l_p=-\int_0^{t'-t_e}\lambda(s)ds.
\end{equation}
Or, we could write this as
\begin{equation}
  l_e =e^{-x}e^{-\int_0^{t0-t_e}\lambda(s)ds}=e^{-x}(1-F(t_0-t_e))
\end{equation}
and
\begin{equation}
  l_e=e^{-\int_0^{t'-t_e}\lambda(s)ds}=1-F(t'-t_e).
\end{equation}
All at once,
\begin{eqnarray}
  F(t'-t_e)&=&1-e^{-x}(1-F(t_0-t_e)) \\
 t'&=&t_e+F^{-1}\left(1-e^{-x}(1-F(t_0-t_e))\right). \\
 F(t_0-t_e)&=&\mbox{gamma\_p}(\alpha,\beta(t_0-t_e)) \\
 F^{-1}(y)&=&\mbox{gamma\_p\_inv}(\alpha, y)/\beta
\end{eqnarray}
So here is our inverse hazard integral.
\begin{lstlisting}
  quad=1-exp(-x)*(1-gamma_p(a,b*(t0-te)))
  tp=te + gamma_p_inv(a, quad)/b
\end{lstlisting}



%%%%%%%%%%%%%%% UNIFORM %%%%%%%%%%%%%%%%%%%

\section{Uniform Distribution}
Maybe this one will be easier.
This distribution has two parameters, a start time
and an end time, $t_a$ and $t_b$.
The pdf is constant, $f(t)=1/(t_b-t_a)$ between
$t_a\le t<t_b$. The CDF is just the integral of
that, $F(t)=(t-t_a)/(t_b-t_a)$.
The integrated hazard will have nonzero cases for
for $t_1<t_a<t_2<t_b$, $t_1<t_a<t_b<t_2$,
$t_a<t_1<t_2<t_b$, $t_a<t_1<t_b<t_2$.
It is zero for $t_1<t_2<t_a$ and $t_a<t_b<t_1<t_2$
\begin{equation}
  \int_{t_1-t_e}^{t_2-t_e}\lambda(s)ds=
      \ln\left[\frac{1-F(t_1-t_e)}{1-F(t_2-t_e)}\right]
\end{equation}
If $t_a\le t_n-t_e<t_b$, then $F(t_n-t_e)=(t_n-t_e-t_a)/(t_b-t_a)$.
Otherwise it is $0$ or $1$. It should never be the
case that a uniform distribution does not fire
before $t_b$. The hazard integral always sums over
time already past in the simulation. Nevertheless, it will
be necessary to check for overflow near $t_b$, and it
would help to keep the two logs separated, instead of
in the fraction.

The integrated hazard for a uniform distribution is unbounded.
It would be fine to create a cutoff close-enough to the
end time, $t_b$. Using $t_{1e}=t_1-t_e$,
\begin{eqnarray}
  \int_{t_1-t_e}^{t_2-t_e}\lambda(s)ds&=&\ln\left[
    \frac{(t_b-t_a)-(t_{1e}-t_a)}{(t_b-t_a)-(t_{2e}-t_a)}\right]
\end{eqnarray}


What about the inverse of the hazard integral?
$F^{-1}(x)=t_a+(t_b-t_a)x$ Therefore, for $t_a\le t_0-t_e$,
\begin{equation}
  t'=t_e+t_a+(t_b-t_a)\left[1-e^{-x}\left(1-\frac{t_0-t_e-t_a}{t_b-t_a}\right)\right]
\end{equation}
and for $t_0-t_e< t_a$,
\begin{equation}
  t'=t_e+t_a+(t_b-t_a)\left[1-e^{-x}\right]
\end{equation}
Multiplying through, this becomes
\begin{equation}
  t'=t_e+t_b-e^{-x}(b-t_0-t_e)
\end{equation}
which is more clearly less than $t_e+t_b$.





\bibliographystyle{ieeetr}
\bibliography{distrib}
\end{document}
